      - name: Fetch and Save Proxies
        run: |
          # Bersihkan file sebelumnya
          > proxies.txt

          # Fungsi untuk mengambil data dengan error handling
          fetch_proxies() {
            url="$1"
            parser="$2"

            if curl -s "$url" | $parser >> proxies.txt; then
              echo "✅ Fetched proxies from $url"
            else
              echo "⚠️ Failed to fetch from $url, skipping..."
            fi
          }

          # Ambil data dari ProxyScrape
          fetch_proxies "https://api.proxyscrape.com/v4/free-proxy-list/get?request=display_proxies&proxy_format=protocolipport&format=text" "cat"

          # Ambil data dari Geonode
          fetch_proxies "https://proxylist.geonode.com/api/proxy-list?filterUpTime=90&limit=500&page=1&sort_by=lastChecked&sort_type=desc" "jq -r '.data[] | .protocols[] as \$proto | \"\(\$proto)://\(.ip):\(.port)\"'"

          # Ambil data dari 911Proxy
          fetch_proxies "https://www.911proxy.com/detection/proxyList?limit=500&page=1&sort_by=lastChecked&sort_type=desc&filterUpTime=90" "jq -r '.data[] | .protocols[] as \$proto | \"\(\$proto)://\(.ip):\(.port)\"'"

          # Ambil data dari LumiProxy (ubah format protokol)
          fetch_proxies "https://api.lumiproxy.com/web_v1/free-proxy/list?page_size=500&page=1&uptime=90&language=en-us" "jq -r '.data.list[] | .protocol as \$p | \"\((\$p == 8 and \"socks5\") // (\$p == 4 and \"socks4\") // (\$p == 2 and \"https\") // (\$p == 1 and \"http\"))://\(.ip):\(.port)\"'"

          # Ambil data dari ProxyServer (43.135.31.113)
          fetch_proxies "http://43.135.31.113:8777/proxyList?limit=500&page=1&uptime=90&language=en-us" "jq -r '.data[] | .protocols[] as \$proto | \"\(\$proto)://\(.ip):\(.port)\"'"

          # Pisahkan berdasarkan jenis
          grep '^http://' proxies.txt > http.txt || true
          grep '^https://' proxies.txt > https.txt || true
          grep '^socks4://' proxies.txt > socks4.txt || true
          grep '^socks5://' proxies.txt > socks5.txt || true
